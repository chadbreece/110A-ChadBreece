{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Implementing Backtracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The objective function is f(x) = x[0]**2 + x[1]**4\n",
    "# 2. The optimal solution is (0, 0) obviously.\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@def   : objective function \n",
    "@param : x is vector \n",
    "@return: a scalar\n",
    "\"\"\"\n",
    "def objective_func(x):\n",
    "    return (x[0] + 2*x[1] - 7)**2 + (2*x[0] + x[1] - 5)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@def   : gradient of objective function \n",
    "@param : x is vector \n",
    "@return: a vector \n",
    "\"\"\"\n",
    "def grad_objective_func(x):\n",
    "    return np.array([10*x[0] + 8*x[1] - 34, 8*x[0] + 10*x[1] - 38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@def   : hessian of objective function \n",
    "@param : x is vector \n",
    "@return: a matrix \n",
    "\"\"\"\n",
    "def hessian_func(x):\n",
    "    return np.matrix([\n",
    "        [10, 8], [8, 10]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a backtracking function\n",
    "def backtracking(f, grad, p, x, c1, ro):\n",
    "    a = 1\n",
    "    while f(x + a*p) > f(x) + c1*a*np.matmul(p,grad(x)):\n",
    "        a = ro*a\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Backtracking Steepest Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The stopping criteria is selected to be 1e-9 for the gradient norm.\n",
    "# The starting point is [5, 5] for this problem\n",
    "# The optimal solution is [0., 0.].\n",
    "\n",
    "x0 = np.array([0, 0])\n",
    "x_opt = np.array([1., 3.])\n",
    "tol = 1e-9\n",
    "c1 = 1e-4\n",
    "ro = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 3.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@def   : exact steepest descent method\n",
    "@param : x is vector \n",
    "@return: a vector \n",
    "\"\"\"\n",
    "def backtracking_steepest_descent(x0):  \n",
    "    x = x0           \n",
    "    p = -grad_objective_func(x) \n",
    "    global count\n",
    "    count = 0\n",
    "    while norm(p) > 1e-9:                                       \n",
    "        a = backtracking(objective_func, grad_objective_func, p, x, c1, ro) \n",
    "        x = x + a*p                   \n",
    "        p = -grad_objective_func(x)         \n",
    "        count += 1\n",
    "    return x\n",
    "\n",
    "\n",
    "x = backtracking_steepest_descent(x0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 3.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@def   : exact steepest descent method\n",
    "@param : x is vector \n",
    "@return: a vector \n",
    "\"\"\"\n",
    "def exact_steepest_descent(x0):             \n",
    "    x = x0                                  \n",
    "    p = -grad_objective_func(x) \n",
    "    global count\n",
    "    count = 0\n",
    "    while norm(p) > 1e-9:                  \n",
    "        def subproblem1d(alpha):            \n",
    "            return objective_func(x + alpha * p)  \n",
    "                                            \n",
    "        res = minimize_scalar(subproblem1d) \n",
    "        x = x + res.x * p                   \n",
    "        p = -grad_objective_func(x) \n",
    "        count += 1\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "x = exact_steepest_descent(x0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 3.]\n"
     ]
    }
   ],
   "source": [
    "alpha = 1e-3\n",
    "\"\"\"\n",
    "@def   : inexact steepest descent method\n",
    "@param : x is vector \n",
    "@return: a vector \n",
    "\"\"\"\n",
    "def inexact_steepest_descent(x0):              \n",
    "    x = x0                                   \n",
    "    p = -grad_objective_func(x) \n",
    "    global count\n",
    "    count = 0\n",
    "    while norm(p) > 1e-9:                    \n",
    "        x = x + alpha * p                    \n",
    "        p = -grad_objective_func(x)          \n",
    "        count += 1\n",
    "    return x\n",
    "\n",
    "\n",
    "x = inexact_steepest_descent(x0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10871"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) The running time is certainly more than exact steepest descent but much much less than inexact. \n",
    "\n",
    "b) With a rho = 0.5 the iterations are reduce then go back up with 0.9. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Backtracking Newton's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@def   : objective function \n",
    "@param : x is vector \n",
    "@return: a scalar\n",
    "\"\"\"\n",
    "def objective_func(x):\n",
    "    return (1-x[0])**2 + 100*(x[1] - x[0]**2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@def   : gradient of objective function \n",
    "@param : x is vector \n",
    "@return: a vector \n",
    "This is a test\n",
    "\"\"\"\n",
    "def grad_objective_func(x):\n",
    "    return np.array([-400*(x[1]-x[0]**2)*x[0]-2*(1-x[0]), 200*(x[1]-x[0]**2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_func(x):\n",
    "    return np.matrix([\n",
    "        [-400*(x[1]-3*x[0]**2)+2, -400*x[0]], [-400*x[0], 200]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 1e-4\n",
    "x0 = np.array([1.2, 1.2])\n",
    "x_opt = np.array([1., 1.])\n",
    "ro = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@def   : exact steepest descent method\n",
    "@param : x is vector \n",
    "@return: a vector \n",
    "\"\"\"\n",
    "def backtracking_steepest_descent(x0):  \n",
    "    x = x0           \n",
    "    p = -grad_objective_func(x) \n",
    "    global count\n",
    "    count = 0\n",
    "    while norm(p) > 1e-9:                                       \n",
    "        a = backtracking(objective_func, grad_objective_func, p, x, c1, ro) \n",
    "        x = x + a*p                   \n",
    "        p = -grad_objective_func(x)         \n",
    "        count += 1\n",
    "    return x\n",
    "\n",
    "\n",
    "x = backtracking_steepest_descent(x0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@def   : Newton's method\n",
    "@param : x is vector \n",
    "@return: a vector \n",
    "\"\"\"\n",
    "def newton_method(x0):\n",
    "    x = x0\n",
    "    p = -grad_objective_func(x)\n",
    "    h = hessian_func(x)\n",
    "    global count\n",
    "    count = 0\n",
    "    while norm(p) > 1e-9:\n",
    "        newton_dir = np.linalg.solve(h, p)\n",
    "        a = backtracking(objective_func, grad_objective_func, p, x, c1, ro)\n",
    "        x = x + a*newton_dir\n",
    "        p = -grad_objective_func(x)\n",
    "        h = hessian_func(x)\n",
    "        count += 1\n",
    "    return x\n",
    "\n",
    "x = newton_method(x0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25543"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At (1.2,1.2), the backtracking steepest descent takes 264 iterations and the backtracking newtons method takes 25000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 1e-4\n",
    "x0 = np.array([-1.2, 1])\n",
    "x_opt = np.array([1., 1.])\n",
    "ro = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "x = backtracking_steepest_descent(x0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "946"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "x = newton_method(x0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28335"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The backtracking steepest descent took about 3.5 times longer while the backtracking newton method took only 0.1 times longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Heavy Ball Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 1e-4\n",
    "x0 = np.array([1.2, 1.2])\n",
    "x_opt = np.array([1., 1.])\n",
    "ro = 0.1\n",
    "a = 1e-3\n",
    "B = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@def   : exact steepest descent method\n",
    "@param : x is vector \n",
    "@return: a vector \n",
    "\"\"\"\n",
    "def heavyball(x0):  \n",
    "    x = [x0]          \n",
    "    p = -grad_objective_func(x[-1]) \n",
    "    global a\n",
    "    x.append(x[-1] + a*p)\n",
    "    global count\n",
    "    count = 0\n",
    "    while norm(p) > 1e-9:                                       \n",
    "        a = backtracking(objective_func, grad_objective_func, p, x[-1], c1, ro) \n",
    "        x.append(x[-1] + a*p + B*(x[-1] - x[-2]))\n",
    "        p = -grad_objective_func(x[-1])         \n",
    "        count += 1\n",
    "    return x[-1]\n",
    "\n",
    "\n",
    "x = heavyball(x0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1553"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 1e-4\n",
    "x0 = np.array([-1.2, 1.])\n",
    "x_opt = np.array([1., 1.])\n",
    "ro = 0.1\n",
    "a = 1e-3\n",
    "B = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.] 1695\n"
     ]
    }
   ],
   "source": [
    "print(heavyball(x0),count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
