{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@def   : objective function \n",
    "@param : x is vector \n",
    "@return: a scalar\n",
    "\"\"\"\n",
    "def objective_func(x):\n",
    "    return (1-x[0])**2 + 100*(x[1] - x[0]**2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@def   : gradient of objective function \n",
    "@param : x is vector \n",
    "@return: a vector \n",
    "This is a test\n",
    "\"\"\"\n",
    "def grad_objective_func(x):\n",
    "    return np.array([2*(200*x[0]**3 - 200*x[0]*x[1] + x[0] - 1), 200*(x[1] - x[0]**2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The exact steepest descent method. \n",
    "# The step length is chosen to solve a one-dimensional optimization problem\n",
    "# The stopping criteria is selected to be 1e-9 for the gradient norm.\n",
    "# The starting point is [5, 5] for this problem\n",
    "# The optimal solution is [0., 0.].\n",
    "\n",
    "x0 = np.array([1.2, 1.2])\n",
    "x_opt = np.array([1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@def   : exact steepest descent method\n",
    "@param : x is vector \n",
    "@return: a vector \n",
    "\"\"\"\n",
    "def exact_steepest_descent(x0):             # input is the starting point\n",
    "    x = x0                                  # select the starting point\n",
    "    p = -grad_objective_func(x)             # find descent direction\n",
    "    while norm(p) > 1e-9:                   # if the norm is not small\n",
    "        def subproblem1d(alpha):            # define a 1d subproblem \n",
    "            return objective_func(x + alpha * p)  \n",
    "                                            # use minimize_scalar function\n",
    "        res = minimize_scalar(subproblem1d) # to solve the subproblem\n",
    "        x = x + res.x * p                   # locate the next iterate\n",
    "        p = -grad_objective_func(x)         # find next descent direction\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "x = exact_steepest_descent(x0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The exact steepest descent method. \n",
    "# The step length is chosen to solve a one-dimensional optimization problem\n",
    "# The stopping criteria is selected to be 1e-9 for the gradient norm.\n",
    "# The starting point is [5, 5] for this problem\n",
    "# The optimal solution is [0., 0.].\n",
    "\n",
    "alpha = 1e-3\n",
    "x0 = np.array([1.2, 1.2])\n",
    "x_opt = np.array([1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@def   : exact steepest descent method\n",
    "@param : x is vector \n",
    "@return: a vector \n",
    "\"\"\"\n",
    "def exact_steepest_descent(x0):             # input is the starting point\n",
    "    x = x0                                  # select the starting point\n",
    "    p = -grad_objective_func(x)             # find descent direction\n",
    "    while norm(p) > 1e-9:                   # if the norm is not small\n",
    "        x = x + alpha * p                   # locate the next iterate\n",
    "        p = -grad_objective_func(x)         # find next descent direction\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "x = exact_steepest_descent(x0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
